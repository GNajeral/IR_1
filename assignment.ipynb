{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import string as st\n",
    "import re\n",
    "from nltk import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Input data files are available in the read-only \"./input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   ArticleId                                               Text\n0       1018  qpr keeper day heads for preston queens park r...\n1       1319  software watching while you work software that...\n2       1138  d arcy injury adds to ireland woe gordon d arc...\n3        459  india s reliance family feud heats up the ongo...\n4       1020  boro suffer morrison injury blow middlesbrough...\n5         51  lewsey puzzle over disallowed try england s jo...\n6       2025  blair blasts tory spending plans tony blair ha...\n7       1479  former ni minister scott dies former northern ...\n8         27  career honour for actor dicaprio actor leonard...\n9        397  tsunami  to hit sri lanka banks  sri lanka s b...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ArticleId</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1018</td>\n      <td>qpr keeper day heads for preston queens park r...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1319</td>\n      <td>software watching while you work software that...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1138</td>\n      <td>d arcy injury adds to ireland woe gordon d arc...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>459</td>\n      <td>india s reliance family feud heats up the ongo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1020</td>\n      <td>boro suffer morrison injury blow middlesbrough...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>51</td>\n      <td>lewsey puzzle over disallowed try england s jo...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2025</td>\n      <td>blair blasts tory spending plans tony blair ha...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1479</td>\n      <td>former ni minister scott dies former northern ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>27</td>\n      <td>career honour for actor dicaprio actor leonard...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>397</td>\n      <td>tsunami  to hit sri lanka banks  sri lanka s b...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data. Here it is already in .csv format.\n",
    "train_data = pd.read_csv('dataset/BBC News Train.csv')\n",
    "test_data = pd.read_csv('dataset/BBC News Test.csv')\n",
    "train_data.head(10)\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(735, 2)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n",
    "test_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text cleaning and processing steps\n",
    "* Remove punctuations\n",
    "* Convert text to tokens\n",
    "* Remove tokens of length less than or equal to 3\n",
    "* Remove stopwords using NLTK corpus stopwords list to match\n",
    "* Apply stemming\n",
    "* Apply lemmatization\n",
    "* Convert words to feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all punctuations from the text\n",
    "\n",
    "def remove_punct(text):\n",
    "    return (\"\".join([ch for ch in text if ch not in st.punctuation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   ArticleId                                               Text  \\\n0       1018  qpr keeper day heads for preston queens park r...   \n1       1319  software watching while you work software that...   \n2       1138  d arcy injury adds to ireland woe gordon d arc...   \n3        459  india s reliance family feud heats up the ongo...   \n4       1020  boro suffer morrison injury blow middlesbrough...   \n\n                                        removed_punc  \n0  qpr keeper day heads for preston queens park r...  \n1  software watching while you work software that...  \n2  d arcy injury adds to ireland woe gordon d arc...  \n3  india s reliance family feud heats up the ongo...  \n4  boro suffer morrison injury blow middlesbrough...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ArticleId</th>\n      <th>Text</th>\n      <th>removed_punc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1018</td>\n      <td>qpr keeper day heads for preston queens park r...</td>\n      <td>qpr keeper day heads for preston queens park r...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1319</td>\n      <td>software watching while you work software that...</td>\n      <td>software watching while you work software that...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1138</td>\n      <td>d arcy injury adds to ireland woe gordon d arc...</td>\n      <td>d arcy injury adds to ireland woe gordon d arc...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>459</td>\n      <td>india s reliance family feud heats up the ongo...</td>\n      <td>india s reliance family feud heats up the ongo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1020</td>\n      <td>boro suffer morrison injury blow middlesbrough...</td>\n      <td>boro suffer morrison injury blow middlesbrough...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['removed_punc'] = train_data['Text'].apply(lambda x: remove_punct(x))\n",
    "test_data['removed_punc'] = test_data['Text'].apply(lambda x: remove_punct(x))\n",
    "train_data.head()\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Convert text to lower case tokens. Here, split() is applied on white-spaces. But, it could be applied\n",
    "    on special characters, tabs or any other string based on which text is to be seperated into tokens.\n",
    "'''\n",
    "def tokenize(text):\n",
    "    text = re.split('\\s+' ,text)\n",
    "    return [x.lower() for x in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   ArticleId                                               Text  \\\n0       1018  qpr keeper day heads for preston queens park r...   \n1       1319  software watching while you work software that...   \n2       1138  d arcy injury adds to ireland woe gordon d arc...   \n3        459  india s reliance family feud heats up the ongo...   \n4       1020  boro suffer morrison injury blow middlesbrough...   \n\n                                        removed_punc  \\\n0  qpr keeper day heads for preston queens park r...   \n1  software watching while you work software that...   \n2  d arcy injury adds to ireland woe gordon d arc...   \n3  india s reliance family feud heats up the ongo...   \n4  boro suffer morrison injury blow middlesbrough...   \n\n                                              tokens  \n0  [qpr, keeper, day, heads, for, preston, queens...  \n1  [software, watching, while, you, work, softwar...  \n2  [d, arcy, injury, adds, to, ireland, woe, gord...  \n3  [india, s, reliance, family, feud, heats, up, ...  \n4  [boro, suffer, morrison, injury, blow, middles...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ArticleId</th>\n      <th>Text</th>\n      <th>removed_punc</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1018</td>\n      <td>qpr keeper day heads for preston queens park r...</td>\n      <td>qpr keeper day heads for preston queens park r...</td>\n      <td>[qpr, keeper, day, heads, for, preston, queens...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1319</td>\n      <td>software watching while you work software that...</td>\n      <td>software watching while you work software that...</td>\n      <td>[software, watching, while, you, work, softwar...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1138</td>\n      <td>d arcy injury adds to ireland woe gordon d arc...</td>\n      <td>d arcy injury adds to ireland woe gordon d arc...</td>\n      <td>[d, arcy, injury, adds, to, ireland, woe, gord...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>459</td>\n      <td>india s reliance family feud heats up the ongo...</td>\n      <td>india s reliance family feud heats up the ongo...</td>\n      <td>[india, s, reliance, family, feud, heats, up, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1020</td>\n      <td>boro suffer morrison injury blow middlesbrough...</td>\n      <td>boro suffer morrison injury blow middlesbrough...</td>\n      <td>[boro, suffer, morrison, injury, blow, middles...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['tokens'] = train_data['removed_punc'].apply(lambda msg : tokenize(msg))\n",
    "test_data['tokens'] = test_data['removed_punc'].apply(lambda msg : tokenize(msg))\n",
    "train_data.head()\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove tokens of length less than 3\n",
    "\n",
    "def remove_small_words(text):\n",
    "    return [x for x in text if len(x) > 3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   ArticleId                                               Text  \\\n0       1018  qpr keeper day heads for preston queens park r...   \n1       1319  software watching while you work software that...   \n2       1138  d arcy injury adds to ireland woe gordon d arc...   \n3        459  india s reliance family feud heats up the ongo...   \n4       1020  boro suffer morrison injury blow middlesbrough...   \n\n                                        removed_punc  \\\n0  qpr keeper day heads for preston queens park r...   \n1  software watching while you work software that...   \n2  d arcy injury adds to ireland woe gordon d arc...   \n3  india s reliance family feud heats up the ongo...   \n4  boro suffer morrison injury blow middlesbrough...   \n\n                                              tokens  \\\n0  [qpr, keeper, day, heads, for, preston, queens...   \n1  [software, watching, while, you, work, softwar...   \n2  [d, arcy, injury, adds, to, ireland, woe, gord...   \n3  [india, s, reliance, family, feud, heats, up, ...   \n4  [boro, suffer, morrison, injury, blow, middles...   \n\n                                       larger_tokens  \n0  [keeper, heads, preston, queens, park, rangers...  \n1  [software, watching, while, work, software, th...  \n2  [arcy, injury, adds, ireland, gordon, arcy, be...  \n3  [india, reliance, family, feud, heats, ongoing...  \n4  [boro, suffer, morrison, injury, blow, middles...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ArticleId</th>\n      <th>Text</th>\n      <th>removed_punc</th>\n      <th>tokens</th>\n      <th>larger_tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1018</td>\n      <td>qpr keeper day heads for preston queens park r...</td>\n      <td>qpr keeper day heads for preston queens park r...</td>\n      <td>[qpr, keeper, day, heads, for, preston, queens...</td>\n      <td>[keeper, heads, preston, queens, park, rangers...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1319</td>\n      <td>software watching while you work software that...</td>\n      <td>software watching while you work software that...</td>\n      <td>[software, watching, while, you, work, softwar...</td>\n      <td>[software, watching, while, work, software, th...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1138</td>\n      <td>d arcy injury adds to ireland woe gordon d arc...</td>\n      <td>d arcy injury adds to ireland woe gordon d arc...</td>\n      <td>[d, arcy, injury, adds, to, ireland, woe, gord...</td>\n      <td>[arcy, injury, adds, ireland, gordon, arcy, be...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>459</td>\n      <td>india s reliance family feud heats up the ongo...</td>\n      <td>india s reliance family feud heats up the ongo...</td>\n      <td>[india, s, reliance, family, feud, heats, up, ...</td>\n      <td>[india, reliance, family, feud, heats, ongoing...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1020</td>\n      <td>boro suffer morrison injury blow middlesbrough...</td>\n      <td>boro suffer morrison injury blow middlesbrough...</td>\n      <td>[boro, suffer, morrison, injury, blow, middles...</td>\n      <td>[boro, suffer, morrison, injury, blow, middles...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['larger_tokens'] = train_data['tokens'].apply(lambda x : remove_small_words(x))\n",
    "test_data['larger_tokens'] = test_data['tokens'].apply(lambda x : remove_small_words(x))\n",
    "train_data.head()\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Remove stopwords. Here, NLTK corpus list is used for a match. However, a customized user-defined \n",
    "    list could be created and used to limit the matches in input text. \n",
    "'''\n",
    "def remove_stopwords(text):\n",
    "    return [word for word in text if word not in nltk.corpus.stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_data['clean_tokens'] = train_data['larger_tokens'].apply(lambda x : remove_stopwords(x))\n",
    "test_data['clean_tokens'] = test_data['larger_tokens'].apply(lambda x : remove_stopwords(x))\n",
    "train_data.head()\n",
    "test_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization converts word to it's dictionary base form. This process takes language grammar and vocabulary into consideration while conversion. Hence, it is different from Stemming in that it does not merely truncate the suffixes to get the root word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Apply lemmatization on tokens\n",
    "def lemmatize(text):\n",
    "    word_net = WordNetLemmatizer()\n",
    "    return [word_net.lemmatize(word) for word in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_data['lemma_words'] = train_data['clean_tokens'].apply(lambda x : lemmatize(x))\n",
    "test_data['lemma_words'] = test_data['clean_tokens'].apply(lambda x : lemmatize(x))\n",
    "train_data.head()\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Create sentences to get clean text as input for vectors\n",
    "\n",
    "def return_sentences(tokens):\n",
    "    return \" \".join([word for word in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_data['clean_text'] = train_data['lemma_words'].apply(lambda x : return_sentences(x))\n",
    "test_data['clean_text'] = test_data['lemma_words'].apply(lambda x : return_sentences(x))\n",
    "train_data.head()\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model and Evaluation Phase"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(data['text'], data['category'], test_size=0.2, random_state=42)\n",
    "X_train = train_data\n",
    "X_train.pop(\"ArticleId\")\n",
    "X_test = test_data\n",
    "X_test.pop(\"ArticleId\")\n",
    "y_train = X_train.pop(\"Category\")\n",
    "y_test = pd.read_csv(\"dataset/BBC News Sample Solution.csv\")\n",
    "y_test.pop(\"ArticleId\")\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#vectorizer = CountVectorizer()\n",
    "#X_train_vec = vectorizer.fit_transform(X_train)\n",
    "#X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# OR\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_and_evaluate(classifier, X_train_vec, y_train, X_test_vec, y_test):\n",
    "    classifier.fit(X_train_vec, y_train)\n",
    "    y_pred = classifier.predict(X_test_vec)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(classifier.__class__.__name__)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(),\n",
    "    LinearSVC(),\n",
    "    RandomForestClassifier(),\n",
    "    KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    train_and_evaluate(classifier, X_train_vec, y_train, X_test_vec, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
