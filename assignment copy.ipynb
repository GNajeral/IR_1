{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IREI: Profile-based retrieval\n",
    "### Víctor Morcuende Castell and Guillermo Nájera Lavid\n",
    "#### Course 2022-2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('dataset/BBC News Train.csv')\n",
    "test_data = pd.read_csv('dataset/BBC News Test.csv')\n",
    "\n",
    "# Transform the data into a single dataset\n",
    "data = pd.concat([train_data,test_data])\n",
    "data.to_csv('dataset/data.csv', index=False)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['Category']).size().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['Category']).size().plot(kind='pie', figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['Category']).size().sort_values(ascending=True).plot(kind='barh', figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all punctuations from the text\n",
    "import string as st\n",
    "\n",
    "def remove_punct(text):\n",
    "    return (\"\".join([ch for ch in text if ch not in st.punctuation]))\n",
    "\n",
    "data['removed_punc'] = data['Text'].apply(lambda x: remove_punct(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to lower case tokens\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    text = re.split('\\s+' ,text)\n",
    "    return [x.lower() for x in text]\n",
    "\n",
    "data['tokens'] = data['removed_punc'].apply(lambda msg : tokenize(msg))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove tokens of length less than 3\n",
    "def remove_small_words(text):\n",
    "    return [x for x in text if len(x) > 3 ]\n",
    "\n",
    "data['larger_tokens'] = data['tokens'].apply(lambda x : remove_small_words(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords by using NLTK corpus list\n",
    "def remove_stopwords(text):\n",
    "    return [word for word in text if word not in nltk.corpus.stopwords.words('english')]\n",
    "\n",
    "data['clean_tokens'] = data['larger_tokens'].apply(lambda x : remove_stopwords(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Apply lemmatization on tokens\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "def lemmatize(text):\n",
    "    word_net = WordNetLemmatizer()\n",
    "    return [word_net.lemmatize(word) for word in text]\n",
    "\n",
    "data['lemma_words'] = data['clean_tokens'].apply(lambda x : lemmatize(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Create sentences to get clean text as input for vectors\n",
    "def return_sentences(tokens):\n",
    "    return \" \".join([word for word in tokens])\n",
    "\n",
    "data['clean_text'] = data['lemma_words'].apply(lambda x : return_sentences(x))\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model and Evaluation Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the dataset to have the same number of documents for each query\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def balance_data(data, category_col):\n",
    "    categories = data[category_col].unique()\n",
    "    min_category_count = data[category_col].value_counts().min()\n",
    "\n",
    "    balanced_data = []\n",
    "\n",
    "    for category in categories:\n",
    "        category_data = data[data[category_col] == category]\n",
    "        category_data_balanced = resample(category_data, replace=False, n_samples=min_category_count, random_state=42)\n",
    "        balanced_data.append(category_data_balanced)\n",
    "\n",
    "    return pd.concat(balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data = balance_data(data, 'Category')\n",
    "X_train, X_test, y_train, y_test = train_test_split(balanced_data['clean_text'], balanced_data['Category'], test_size=0.2, random_state=42)\n",
    "balanced_data.groupby(['Category']).size().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data.groupby(['Category']).size().plot(kind='pie', figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data.groupby(['Category']).size().sort_values(ascending=True).plot(kind='barh', figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "document_vectors = vectorizer.fit_transform(balanced_data['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {\n",
    "    # Sports\n",
    "    'sports': [\"sports\", \"championship\", \"soccer\", \"race\", \"football\", \"tennis\", \"baseball\", \"hockey\", \"basketball\", \"athletics\", \"rugby\", \"swimming\", \"golf\", \"cycling\", \"cricket\", \"marathon\", \"gymnastics\", \"boxing\", \"volleyball\", \"badminton\", \"fencing\", \"wrestling\", \"snowboarding\", \"skiing\", \"horse-racing\", \"archery\", \"table-tennis\", \"e-sports\", \"fitness\", \"olympics\"],\n",
    "    \n",
    "    # Business\n",
    "    'business': [\"business\", \"finance\", \"stocks\", \"economy\", \"investment\", \"entrepreneurship\", \"corporation\", \"market\", \"trade\", \"revenue\", \"profit\", \"startup\", \"loss\", \"growth\", \"acquisition\", \"tax\", \"debt\", \"funding\", \"venture\", \"capital\", \"inflation\", \"interest\", \"dividends\", \"corporate\", \"management\", \"banking\", \"insurance\", \"real-estate\", \"franchise\", \"supply-chain\"],\n",
    "    \n",
    "    # Entertainment\n",
    "    'entertainment': [\"entertainment\", \"movies\", \"music\", \"television\", \"celebrities\", \"awards\", \"festivals\", \"concert\", \"theater\", \"comedy\", \"drama\", \"action\", \"romance\", \"animation\", \"documentary\", \"dance\", \"art\", \"literature\", \"photography\", \"sculpture\", \"painting\", \"opera\", \"magic\", \"circus\", \"museum\", \"exhibition\", \"actor\", \"actress\", \"singer\", \"culture\"],\n",
    "    \n",
    "    # Politics\n",
    "    'politics': [\"politics\", \"government\", \"elections\", \"policy\", \"democracy\", \"president\", \"parliament\", \"vote\", \"prime-minister\", \"congress\", \"senate\", \"international\", \"relations\", \"diplomacy\", \"referendum\", \"constitution\", \"legislation\", \"political-party\", \"campaign\", \"debate\", \"rights\", \"protest\", \"activism\", \"military\", \"intelligence\", \"treaty\", \"embassy\", \"visa\", \"immigration\", \"trade-agreements\"],\n",
    "    \n",
    "    # Tech\n",
    "    'tech': [\"tech\", \"technology\", \"innovation\", \"gadgets\", \"smartphone\", \"artificial-intelligence\", \"robotics\", \"software\", \"hardware\", \"computer\", \"internet\", \"cybersecurity\", \"virtual-reality\", \"augmented-reality\", \"machine-learning\", \"data-science\", \"blockchain\", \"cryptocurrency\", \"internet-of-things\", \"cloud-computing\", \"big-data\", \"quantum-computing\", \"networking\", \"operating-system\", \"mobile-apps\", \"programming\", \"research\", \"drones\", \"3D-printing\", \"wearables\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [\n",
    "    {'id': 1, 'interests': ['sports']},\n",
    "    {'id': 2, 'interests': ['business']},\n",
    "    {'id': 3, 'interests': ['entertainment']},\n",
    "    {'id': 4, 'interests': ['politics']},\n",
    "    {'id': 5, 'interests': ['tech']},\n",
    "    {'id': 6, 'interests': ['sports', 'business']},\n",
    "    {'id': 7, 'interests': ['entertainment', 'politics']},\n",
    "    {'id': 8, 'interests': ['tech', 'sports']},\n",
    "    {'id': 9, 'interests': ['business', 'entertainment']},\n",
    "    {'id': 10, 'interests': ['politics', 'tech', 'business']}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a dictionary with user interests as keys and user IDs as values\n",
    "interests_users = {}\n",
    "for user in users:\n",
    "    user_id = user['id']\n",
    "    for interest in user['interests']:\n",
    "        if interest not in interests_users:\n",
    "            interests_users[interest] = [user_id]\n",
    "        else:\n",
    "            interests_users[interest].append(user_id)\n",
    "\n",
    "# Step 2: Convert user interests into interest vectors using the vectorizer\n",
    "interest_vectors = {}\n",
    "for interest, keywords in topics.items():\n",
    "    interest_vector = vectorizer.transform([' '.join(keywords)])\n",
    "    interest_vectors[interest] = interest_vector\n",
    "\n",
    "# Step 3: Calculate cosine similarity between the document and interest vectors\n",
    "def recommend_users(doc_vector, interest_vectors, interests_users, threshold=0.1):\n",
    "    recommended_users = set()\n",
    "    for interest, interest_vector in interest_vectors.items():\n",
    "        similarity = cosine_similarity(doc_vector, interest_vector)\n",
    "        if similarity >= threshold:\n",
    "            recommended_users.update(interests_users[interest])\n",
    "    return recommended_users\n",
    "\n",
    "# Step 4: Recommend documents to users based on their cosine similarity scores\n",
    "doc_recommendations = {}\n",
    "for index, row in data.iterrows():\n",
    "    doc_vector = vectorizer.transform([row['clean_text']])\n",
    "    recommended_users = recommend_users(doc_vector, interest_vectors, interests_users)\n",
    "    doc_recommendations[row['Text']] = recommended_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Precision, Recall, and F1 score\n",
    "def evaluate_performance(doc_recommendations, data, users, topics):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    for doc, recommended_users in doc_recommendations.items():\n",
    "        true_category = data[data['Text'] == doc]['Category'].values[0]\n",
    "        true_interests = set(topics[true_category])\n",
    "\n",
    "        for user in users:\n",
    "            user_id = user['id']\n",
    "            user_interests = set(user['interests'])\n",
    "\n",
    "            if user_id in recommended_users:\n",
    "                if user_interests.intersection(true_interests):\n",
    "                    true_positives += 1\n",
    "                else:\n",
    "                    false_positives += 1\n",
    "            else:\n",
    "                if user_interests.intersection(true_interests):\n",
    "                    false_negatives += 1\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "precision, recall, f1_score = evaluate_performance(doc_recommendations, data, users, topics)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    user_interests = \" \".join(user['interests'])\n",
    "    user_vec = vectorizer.transform([user_interests])\n",
    "    user['vector'] = user_vec\n",
    "\n",
    "user_list = [user['vector'] for user in users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "  random_index = random.randint(0, len(balanced_data['clean_text'])-1) #get a random document from the dataset\n",
    "  incoming_doc_vector = document_vectors[random_index]\n",
    "  list_sim = []\n",
    "\n",
    "  profiles = []\n",
    "\n",
    "  for j in range(len(user_list)):\n",
    "    similarities = cosine_similarity(incoming_doc_vector, user_list[j]) #cosine distance between the document and the users\n",
    "    if similarities[0][0] > 0.0: #all values that are not 0 are saved\n",
    "      profiles.append(j+1)\n",
    "      list_sim.append(similarities[0][0])\n",
    "  \n",
    "  #return the document, the users thar are going to receive that document and the main topic related to the document\n",
    "  print(\"For document\",i+1, \":\", balanced_data['clean_text'][random_index])\n",
    "  print()\n",
    "  print(\"Categorized as: \"+ balanced_data['Category'][random_index]+ ' topic.')\n",
    "  print()\n",
    "  print(\"The user who are interested in this document are\", profiles)\n",
    "  print()\n",
    "\n",
    "  print(\"RANKING\")\n",
    "  print()\n",
    "  ranking = pd.DataFrame()\n",
    "  ranking[\"Users\"] = profiles\n",
    "  ranking[\"Score\"] = list_sim\n",
    "  ranking = ranking.sort_values('Score', ascending=False)\n",
    "  print(ranking)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Term Frequency-Inverse Document Frequency (TF-IDF) to assign weights to words in each topic.\n",
    "def create_topic_vectors(topics):\n",
    "    topic_texts = [' '.join(keywords) for keywords in topics.values()]\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(topic_texts)\n",
    "\n",
    "    topic_vectors = {}\n",
    "    for i, (topic, words) in enumerate(topics.items()):\n",
    "        vector = tfidf_matrix[i].toarray()[0]\n",
    "        topic_vectors[topic] = vector\n",
    "    return topic_vectors, tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If decay_exponent is set to 0, all interests will have equal weights regardless of their position in the list.\n",
    "If decay_exponent is set to 1, the decay factor is linear, and the weights will decrease proportionally to the position in the list.\n",
    "If decay_exponent is set to a value greater than 1, the decay factor will decrease more rapidly, giving more emphasis to the first interest and significantly less to the subsequent interests.\n",
    "If decay_exponent is set to a value between 0 and 1, the decay factor will decrease more slowly, making the weights more evenly distributed among the interests.\n",
    "You can experiment with different values for decay_exponent to find the balance that best suits your needs. Keep in mind that setting an extremely high \n",
    "decay_exponent will result in almost entirely ignoring interests lower in the list, so it's essential to find a balance that works for your specific use case.\n",
    "'''\n",
    "\n",
    "def create_user_profiles(users, topic_vectors, decay_exponent):\n",
    "    user_profiles = []\n",
    "\n",
    "    for user in users:\n",
    "        user_interests = user['interests']\n",
    "        aggregated_vector = np.zeros(len(topic_vectors[next(iter(topic_vectors))]), dtype=float)\n",
    "        total_weight = 0\n",
    "\n",
    "        for i, interest in enumerate(user_interests):\n",
    "            weight = 1 / (i + 1) ** decay_exponent\n",
    "            total_weight += weight\n",
    "            topic_vector = topic_vectors[interest]\n",
    "            aggregated_vector += weight * topic_vector\n",
    "\n",
    "        # Normalize the aggregated vector\n",
    "        aggregated_vector /= total_weight\n",
    "        \n",
    "        user_profiles.append({\n",
    "            'id': user['id'],\n",
    "            'profile': aggregated_vector\n",
    "        })\n",
    "\n",
    "    return user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cosine_similarity_with_profiles(text, vectorizer, user_profile):\n",
    "    text_vec = vectorizer.transform([text])\n",
    "    profile_vec = user_profile['profile'].reshape(1, -1)\n",
    "    similarity = cosine_similarity(text_vec, profile_vec)\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a dictionary with user interests as keys and user IDs as values\n",
    "interests_users = {}\n",
    "for user in users:\n",
    "    user_id = user['id']\n",
    "    for interest in user['interests']:\n",
    "        if interest not in interests_users:\n",
    "            interests_users[interest] = [user_id]\n",
    "        else:\n",
    "            interests_users[interest].append(user_id)\n",
    "\n",
    "# Step 2: Convert user interests into interest vectors using the vectorizer\n",
    "interest_vectors = {}\n",
    "for interest, keywords in topics.items():\n",
    "    interest_vector = vectorizer.transform([' '.join(keywords)])\n",
    "    interest_vectors[interest] = interest_vector\n",
    "\n",
    "# Step 3: Calculate cosine similarity between the document and interest vectors\n",
    "def recommend_users(doc_vector, interest_vectors, interests_users, threshold=0.1):\n",
    "    recommended_users = set()\n",
    "    for interest, interest_vector in interest_vectors.items():\n",
    "        similarity = cosine_similarity(doc_vector, interest_vector)\n",
    "        if similarity >= threshold:\n",
    "            recommended_users.update(interests_users[interest])\n",
    "    return recommended_users\n",
    "\n",
    "# Step 4: Recommend documents to users based on their cosine similarity scores\n",
    "doc_recommendations = {}\n",
    "for index, row in data.iterrows():\n",
    "    doc_vector = vectorizer.transform([row['clean_text']])\n",
    "    recommended_users = recommend_users(doc_vector, interest_vectors, interests_users)\n",
    "    doc_recommendations[row['Text']] = recommended_users\n",
    "\n",
    "print(doc_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_deliver_document(text, vectorizer, user_profile, threshold):\n",
    "    similarity = test_cosine_similarity_with_profiles(text, vectorizer, user_profile)\n",
    "    return similarity >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_vectors, tfidf_vectorizer = create_topic_vectors(topics)\n",
    "user_profiles = create_user_profiles(users, topic_vectors, decay_exponent=1)\n",
    "\n",
    "# Example document\n",
    "document = \"Today the stock market experienced significant growth, with several companies reporting increased profits.\"\n",
    "\n",
    "# Threshold for cosine similarity\n",
    "threshold = 0.5\n",
    "\n",
    "# Check if the document should be delivered to each user\n",
    "for user_profile in user_profiles:\n",
    "    if should_deliver_document(document, tfidf_vectorizer, user_profile, threshold):\n",
    "        print(f\"Deliver the document to user {user_profile['id']}\")\n",
    "    else:\n",
    "        print(f\"Do not deliver the document to user {user_profile['id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = CountVectorizer()\n",
    "#X_train_vec = vectorizer.fit_transform(X_train)\n",
    "#X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# OR\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_df=0.9, min_df=5)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = y_train.unique()\n",
    "category_avg_vecs = {}\n",
    "\n",
    "for category in categories:\n",
    "    category_indices = y_train[y_train == category].index\n",
    "    category_vectors = X_train_vec[category_indices, :]\n",
    "    category_avg_vec = np.mean(category_vectors, axis=0)\n",
    "    category_avg_vecs[category] = category_avg_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(text, vectorizer, category_avg_vecs):\n",
    "    text_vec = vectorizer.transform([text])\n",
    "    max_similarity = -1\n",
    "    predicted_category = None\n",
    "\n",
    "    for category, avg_vec in category_avg_vecs.items():\n",
    "        similarity = cosine_similarity(text_vec, np.asarray(avg_vec))\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            predicted_category = category\n",
    "\n",
    "    return predicted_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [predict_category(text, vectorizer, category_avg_vecs) for text in X_test]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(classifier, X_train_vec, y_train, X_test_vec, y_test):\n",
    "    classifier.fit(X_train_vec, y_train)\n",
    "    y_pred = classifier.predict(X_test_vec)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    print(classifier.__class__.__name__)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    performance = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": classification_report_dict[\"macro avg\"][\"precision\"],\n",
    "        \"recall\": classification_report_dict[\"macro avg\"][\"recall\"],\n",
    "        \"f1_score\": classification_report_dict[\"macro avg\"][\"f1-score\"],\n",
    "    }\n",
    "    \n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics = {}\n",
    "\n",
    "classifiers = [\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(),\n",
    "    LinearSVC(),\n",
    "    RandomForestClassifier(),\n",
    "    KNeighborsClassifier()\n",
    "]\n",
    "\n",
    "\n",
    "for classifier in classifiers:\n",
    "    performance_metrics[classifier.__class__.__name__] = train_and_evaluate(classifier, X_train_vec, y_train, X_test_vec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for classifier, metrics in performance_metrics.items():\n",
    "    print(f\"{classifier}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate_with_cross_val(classifier, X, y, n_splits=5):\n",
    "    scores = cross_val_score(classifier, X, y, cv=n_splits)\n",
    "    return np.mean(scores)\n",
    "\n",
    "X_vec = vectorizer.fit_transform(data['clean_text'])\n",
    "y = data['Category']\n",
    "\n",
    "for classifier in classifiers:\n",
    "    mean_score = evaluate_with_cross_val(classifier, X_vec, y)\n",
    "    print(f\"{classifier.__class__.__name__}: {mean_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def plot_cm(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm_normalized, annot=True, cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "class_names = data['Category'].unique()\n",
    "\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train_vec, y_train)\n",
    "    y_pred = classifier.predict(X_test_vec)\n",
    "    print(f\"Confusion Matrix for {classifier.__class__.__name__}:\")\n",
    "    plot_cm(y_test, y_pred, class_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top N keywords for each category\n",
    "def top_n_keywords_by_category(X_train_vec, y_train, vectorizer, n=20):\n",
    "    categories = y_train.unique()\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "    \n",
    "    top_keywords = {}\n",
    "    \n",
    "    for category in categories:\n",
    "        category_indices = y_train[y_train == category].index\n",
    "        category_vectors = X_train_vec[category_indices, :]\n",
    "        category_sum_vec = np.sum(category_vectors, axis=0)\n",
    "        \n",
    "        sorted_indices = np.argsort(category_sum_vec).flatten()[::-1]\n",
    "        top_n_indices = sorted_indices[:n]\n",
    "        top_n_keywords = feature_names[top_n_indices]\n",
    "        \n",
    "        top_keywords[category] = top_n_keywords.tolist()\n",
    "    \n",
    "    return top_keywords\n",
    "\n",
    "# Test the performance using the keyword profiles\n",
    "def test_cosine_similarity_with_profiles(text, vectorizer, category_profiles):\n",
    "    text_vec = vectorizer.transform([text])\n",
    "    max_similarity = -1\n",
    "    predicted_category = None\n",
    "\n",
    "    for category, profile_keywords in category_profiles.items():\n",
    "        profile_vec = vectorizer.transform([' '.join(map(str, profile_keywords))])\n",
    "        similarity = cosine_similarity(text_vec, profile_vec)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            predicted_category = category\n",
    "\n",
    "    return predicted_category\n",
    "\n",
    "# Create better category profiles\n",
    "category_profiles = top_n_keywords_by_category(X_train_vec, y_train, vectorizer, n=20)\n",
    "\n",
    "# Test the performance\n",
    "y_pred_profiles = [test_cosine_similarity_with_profiles(text, vectorizer, category_profiles) for text in X_test]\n",
    "\n",
    "# Calculate accuracy and display results\n",
    "accuracy_profiles = accuracy_score(y_test, y_pred_profiles)\n",
    "print(f\"Accuracy with keyword profiles: {accuracy_profiles:.4f}\")\n",
    "\n",
    "print(\"Classification Report with keyword profiles:\\n\", classification_report(y_test, y_pred_profiles))\n",
    "\n",
    "cm_profiles = confusion_matrix(y_test, y_pred_profiles)\n",
    "print(\"Confusion Matrix with keyword profiles:\\n\", cm_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the performance using the keyword profiles\n",
    "y_pred_profiles = [test_cosine_similarity_with_profiles(text, vectorizer, category_profiles) for text in X_test]\n",
    "\n",
    "# Calculate accuracy and display results\n",
    "accuracy_profiles = accuracy_score(y_test, y_pred_profiles)\n",
    "print(f\"Accuracy with keyword profiles: {accuracy_profiles:.4f}\")\n",
    "\n",
    "print(\"Classification Report with keyword profiles:\\n\", classification_report(y_test, y_pred_profiles))\n",
    "\n",
    "cm_profiles = confusion_matrix(y_test, y_pred_profiles)\n",
    "print(\"Confusion Matrix with keyword profiles:\\n\", cm_profiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfdml_plugin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8eb26be180a0cf5b5323ae355caa2b1523e608ab9e6cb89b14d3325352809724"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
